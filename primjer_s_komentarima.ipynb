{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. korak - učitavanje potrebnih biblioteka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učitavanje svih potrebnih PyTorch biblioteka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učitavanje standardnih Python paketa za data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from plotcm import plot_confusion_matrix\n",
    "\n",
    "import pdb\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. korak -  dataset i dataloader\n",
    "Pored njihovog stvaranja ćemo također nešto detaljnije zaviriti u dataset i pogledati kako su slike spremljene u njemu. Za stvaranje dataseta i dataloadera koristimo PyTorch razrede:\n",
    "- torch.utils.data.Dataset\n",
    "- torch.utils.data.DataLoader\n",
    "\n",
    "Za istancu FashionMNIST dataseta koristimo torchvision koji sam dohvaća dataset koji zatražimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'     #Lokacija gdje želimo spremati dohvaćene podatke\n",
    "    ,train=True       #True ako je dataset za treniranje\n",
    "    ,download=True    #True ukoliko bi dataset trebao biti skinut\n",
    "    ,transform=transforms.Compose([\n",
    "        #Kompozicija transformacija koje će se izvesti nad elementom dataseta\n",
    "        #Ovdje želimo sve učitane slike pretvoriti u tensor objekte\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stvorimo Dataloader wrapper za učitani training set. Dataloader omata dataset te osigurava kasnije potrebnu funkcionalnost pristupa podatcima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set\n",
    "    ,batch_size=1000\n",
    "    ,shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pogledajmo najprije što je u train_set. Koja je duljina tog tenzora? Koji su labeli unutar njega? Je li dataset homogen - odnosno je li ima jednak broj slika svake klase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set)) #Duljina seta\n",
    "print(train_set.targets)  #Koji su labeli točne klasifikacije\n",
    "print(train_set.targets.bincount()) # Provjerimo je li set balansiran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zavirimo u prvu sliku iz seta. Pytonov način za dobiti prvi element iz nečega iterabilnog je općenito next(iter(neki_iterabilni_objekt)), gdje iter() dohvati iterator nad iterabilnim objektom, a next uzme sljedeći element iteratora.\n",
    "Zanima nas kako izgledaju pohranjeni podatci u datasetu i zato dobiveni uzorak _sample_ razdvajamo najprije na njegove dvije komponente - sliku i label, a dalje doznamo da je slika tenzor dimenzija 1x28x28, a label obični integer gdje broj 9 označava da slika prikazuje gležnjaču. Sliku iscrtavamo pomoću biblioteke matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_set)) \n",
    "\n",
    "image, label = sample #Na prvom mjesto uzorka je slika, na drugom label\n",
    "print('types:', type(image), type(label)) #Koje su vrste slika odnosno label\n",
    "print('shapes:', image.shape, torch.tensor(label).shape) #Kojeg su oblika\n",
    "#Label je samo broj (int) pa ga moramo najprije upakirati da bi doznali shape\n",
    "print(image.squeeze().shape) #Primjetimo da squeeze izbaci jediničnu dimenziju\n",
    "\n",
    "#Iscrtavanje uzorka pomoću matplotlib biblioteke\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "print(\"Ova slika je klase: \", torch.tensor(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pogledajmo također kako izgleda jedan batch podataka. Batch podataka se odnosi na veću skupinu slika koje ćemo kasnije htjeti zajedno obraditi. Preciznije, govori broj slika koje koristimo u svakoj iteraciji pri treniranju ili testiranju modela mreže. Ovdje ćemo prikazati samo batch od 10 slika, a kasnije ćemo koristiti batch od po 1000 slika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_loader = torch.utils.data.DataLoader( train_set, batch_size=10 )\n",
    "batch = next(iter(display_loader)) # uzmimo prvi batch podataka od loadera\n",
    "\n",
    "images, labels = batch #Raspakirajmo batch na slike i labele\n",
    "print('types:', type(images), type(labels)) #Tipovi slika i labela\n",
    "print('shapes:', images.shape, labels.shape) #Oblici slika i labela\n",
    "print(images[0].shape) # oblik prve slike\n",
    "print(labels[0]) #Klasifikacija prve slike\n",
    "\n",
    "#Stvorimo grid koji možemo iscrtati uz pomoć torchvision.utils\n",
    "grid = torchvision.utils.make_grid(images, nrow=10)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "\n",
    "print('labels:', labels) #ispišimo i pripadajuće labele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. korak - modeliranje neuronske mreže \n",
    "Nakon što smo vidjeli kako učitati potrebne podatke, krenimo na izgradnju neuronske mreže. Prvi korak u tome je izgradnja arhitekture, odnosno definiranje slojeva koji je sačinjavaju i definiranje propagacije unaprijed koju određuje metoda forward.\n",
    "\n",
    "Sve neuronske mreže moraju nasljediti razred torch.nn.Module. Slojevi mreže također nasljeđuju taj razred. U ovom kodu koristimo dvije vrste slojeva - konvolucijski sloj modeliran razredom torch.nn.Conv2d i linearni tj. potpuno povezani sloj modeliran razredom torch.nn.Linear.\n",
    "\n",
    "Pri definiranju propagacije unaprijed, bitan je pojam funkcija aktivacije. Funckije aktivacije određuju kako pojedinačni neuroni reagiraju na dospjele \"podražaje\", odnosno govore koliko će se neuron aktivirati za dospjele signale iz prethodnog sloja. Kao funkcija aktivacije se najčešće koriste ReLU i sigmoida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        #Stvorimo dva konvolucijska sloja\n",
    "        #konvolucijski slojevi su modelirani razredom torch.nn.Conv2d\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        #Stvorimo dva linearna sloja\n",
    "        #fc kao \"fully connected layer\", a ima i drugi naziv - \"linear layer\"\n",
    "        #linearni slojevi su modelirani razredom torch.nn.Linear\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        #Stvaranje izlaznog sloja - sloja gdje vidimo rezultate predikcije\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t) #funkcija aktivacije\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t) #funkcija aktivacije\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12 * 4 * 4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t) #funkcija aktivacije\n",
    "\n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t) #funkcija aktivacije\n",
    "\n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neke parametre koje smo koristili pri definiranju arhitekture smo sami odabrali,a njih nazivamo hiperparametri. Hiperparametri su parametri čije se vrijednosti biraju ručno i proizvoljno. Programer neuronskih mreža bira te vrijednosti uglavnom na temelju pokušaja i pogreške, promatrajući koji paramteri će dati bolje rezultate i vodeći se vrijednostima koje su se pokazale uspješnima u prošlosti. Za izgradnju arhitekture definirane konvolucijske mreže smo sada odabrali sljedeće hiperparametre: kernel_size, out_channels i out_features. Već smo ranije odabrali i hiperparametar veličinu batcha. Vrijednosti hiperparametara jednostavno sami odabiremo te testiramo i podešavamo kako bismo pronašli vrijednosti koje najbolje funkcioniraju.\n",
    "\n",
    "Kratak opis spomenutih parametara:\n",
    "- kernel_size - Postavlja veličinu filtra u korištenog u konvolucijskom sloju. Riječi kernel i filter su međusobno zamjenjive. kernel_size=5 odgovara filtru dimenzija 5x5\n",
    "- out_channels - Postavlja broj filtara. Jedan filtar proizvodi jedan izlazni kanal.\n",
    "- out_features - Postavlja veličinu izlaznog tensora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stvorimo instancu neuronske mreže te ju ispišimo. PyTorch osigurava da ispis modela neuronske mreže prikaže i opiše slojeve koji čine tu mrežu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. korak - definirati funkciju treniranja\n",
    "\n",
    "Treniranje se ugrubo odvija u ovim koracima:\n",
    "1. Dohvati batch\n",
    "2. Predaj dohvaćeni batch mreži\n",
    "3. Izračunaj koliko je mreža pogriješila pomoću funkcije gubitka\n",
    "4. Izračunaj gradijent funkcije gubitke s obzirom na parametre u slojevima mreža (težine)\n",
    "5. Ažuriraj parametre mreže na temelju odgovarajućeg gradijenta i to tako da napraviš korak određene veličine u negativnom smjeru gradijenta\n",
    "6. Ponavljaj korake 1-5 dok se ne dovrši jedna epoha, a epoha znači preći jednom preko svih podataka što su u datasetu za treniranje\n",
    "7. Ponavljaj korake 1-6 dok se ne odradi zadani broj epoha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri definiranju funkcije treniranja ključni su sljedeći hiperparametri:\n",
    "\n",
    "- funckija gubitka (loss) - funkcija koja za predikcije mreže očitane na izlaznom sloju kaže koliko je mreža pogriješila, da bi se mreža na temelju toga i korištenjem diferencijacije popravila. Neke funkcije gubitka su MSE ( _Mean Square Error_ ), MAE ( _Mean Absolute Error_ ), MBE ( _Mean Bias Error_ )\n",
    "- funkcija optimizacije (optimizer) - da bi mreža učila, koristi propagaciju unazad - dakle od izlaznog sloja krene prema ulaznom sloju. Pritom na svaki parametar svakog sloja primjeni funkciju optimizacije kojom napravi korak određene veličine u negativnom smjeru gradijenta. Najkorištenije funkcije optimizacije su Adam ( _Adaptive Moment Estimation_ ), SGD ( _Stochastic gradient descent_ ) i RMSProp ( _Root Mean Squared Propagation_ )\n",
    "- learning rate - početna veličina koraka koju mreža napravi u negativnom smjeru derivacije funkcije gubitka za svaki parametar koji se nalazi u težinama slojeva mreže kada se mreža optimizira. Veličina koraka se tijekom učenja prilagođava, točnije smanjuje kako se bliži minimumu funckije gubitka.\n",
    "- broj epoha - koliko puta ćemo preći preko svih podataka iz dataseta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss() # funkcija gubitka\n",
    "optimizer_f = torch.optim.Adam # funkcija optimizacije\n",
    "learning_rate = 0.005 # početna veličina koraka \n",
    "epochs = 6 #broj epoha\n",
    "\n",
    "def train():\n",
    "    model = Network()\n",
    "    optimizer = optimizer_f(model.parameters(), lr = learning_rate)\n",
    "    criterion = loss_f\n",
    "    for epoch in range(1, epochs):\n",
    "        for batch_id, (image, label) in enumerate(train_loader):\n",
    "            label, image = label, image\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_id % 10 == 0:\n",
    "                # print tek da vidimo kako teče treniranje\n",
    "                print('Loss :{:.4f} Epoch[{}/{}]'.format(loss.item(),epoch,6))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. korak - treniranje mreže\n",
    "\n",
    "Pogledajmo najprije koje su predikcije neistrenirane mreže za prije izvađeni uzorak - sliku gležnjače koja ima label 9. Nakon što provučemo izlaz kroz softmax funckiju, dobit ćemo vjerojatnosti u postotcima. Primjetimo da su vjerojatnosti nasumično raspoređene jer su trenutni parametri mreže također nasumično uzeti pri inicijalizaciji mreže. Postotci s kreću oko 10% za sve klase, što je za očekivati jer je ukupno 10 klasa, a 1/10 = 0.1 --> 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = network(image.unsqueeze(0))\n",
    "print(pred)\n",
    "print(F.softmax(pred, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenirajmo mrežu tako što pridodjelimo istreniranu mrežu prije definiranom modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provjerimo koje predikcije istrenirane mreže na istu onu sliku gležnjače od prije. Primjetimo da je vjerojatnost koju sada predviđa mreža za gležnjaču značajno veća i točnija za label 9 koji odgovara klasi gležnjače te iznosi 99.561%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(image.unsqueeze(0))\n",
    "print(pred)\n",
    "print(F.softmax(pred, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. korak - testiranje istrenirane mreže\n",
    "\n",
    "Najprije dohvatimo dataset za testiranje, a potom definiramo funkciju koja će odraditi testiranje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=False\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(train_set\n",
    "    ,batch_size=1000\n",
    "    ,shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for image, label in test_loader:\n",
    "            image = image#.to(device)\n",
    "            label = label#.to(device)\n",
    "            outputs = model(image)\n",
    "            predicted = torch.argmax(outputs,dim=1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "        msg='Test Accuracy of the model on the test images: {} %'\n",
    "        print(msg.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testirajmo mrežu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testiranje krenulo...\")\n",
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
